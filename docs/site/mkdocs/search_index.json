{
    "docs": [
        {
            "location": "/", 
            "text": "Soundcast Users' Guide\n\n\nThe Soundcast model package includes all estimated and calibrated demand models and scripts to assign demand onto road and transit networks. Soundcast's demand models were developed as part of the DaySim activity model framework by consultants \nRSG\n. As shown in the figure below, the demand models process land use, demographics, and network inputs to produce trip tables by user class and time of day. These trips (i.e., 'demand') are then assigned to travel networks using \nINRO's Emme software\n. If network assignment hasn't yet reached equilibrium, cost and time skims are sent back to the DaySim demand models to produce trip tables that incorporate network conditions from the latest model iteration. Upon convergence (specified as a configurable parameter) the model estimation will conclude and produce summary reports. \n\n\n\n\nHardware Recommendations\n\n\n- 100 GB disk space for each model run\n- 32 GB RAM recommended\n- Minimum of 12 processors\n\n\n\n(Soundcast can be run on machines with less memory and fewer processors, but run time will be extended.)\n\n\nSoftware Recommendations\n\n\n- INRO Emme 4 License, with capability for processing 4000-zone matrices\n- Only tested on 64-bit Windows 7 OS\n- Anaconda Python Package (Python 2.7 with helper libraries included)\n\n\n\nInitial Setup\n\n\nAll Soundcast scripts are stored within a public \nGitHub repository\n. If you're familiar with Git technology, you can \nclone\n the repository on your modeling machine. \n\n\nAlternatively, you can download all the code as a ZIP file. \n\n\n\n\nPython Packages and Paths\n\n\nIt's recommended to \ninstall the Anaconda Python package\n to run Soundcast. This package should include all necessary libraries to run the model. When installing, make sure the installer adds the Anaconda install to the system path (or add it yourself after installing). It's important that this install is the one referenced whenever the \"python\" program is invoked from a command. Many machines might include another Python install; it's okay to leave other versions installed, but you'll want to update the path variable to point only to the Anaconda version. In order to avoid conflicts with Emme's Python install, \ndownload package version 2.2.0.\n \nClick here to directly download Anaconda 2.2.0 for 64-bit Windows\n. Additionally, you may want to install Anaconda for current users only (not for all users). Sometimes installing Python for all users will conflict with administrative rights, so it's best to install and use it as a local user. \n\n\nAfter installing Anaconda, you must change Emme's settings to use the Anaconda installation by default. Otherwise, scripts that interact with Emme will use another install without the necessary libraries. To change the Python version used by Emme, select Tools (from the main taskbar) and click 'Application Options'. Under the Modeller tab is a field \"Python path\", which by default probably looks like:\n\n\n%\n$EmmePath\n%/Python27\n\n\n\n\n\nReplace this path with the full path to the Anaconda Python executable (python.exe). Depending on where Anaconda was installed, it may be something like:\n\n\nC:\\Anaconda\n\n\n\nTroubleshooting Python Install\n\n\nEmme's Python libraries can conflict with the Anaconda install used to run Python. As of Emme release 4.2.3, there are two known conflicts with the Anaconda libraries. Two libraries \"ply\" and \"pyqt\" from Anaconda clash with Emme. INRO's solution is to remove these two libraries from the Anaconda install and rely on the Emme libraries. This works for Anaconda 2.2.0 and prior releases, but does not work for the latest versions. For now, the recommended approach is to use Anaconda 2.2.0 and remove ply and pyqt libraries. This can be done from the command prompt with \"conda uninstall ply\" and \"condat uninstall pyqt\". When these libraries are removed from Anaconda, Emme will look to its local install of these packages, which should have no conflicts.\n\n\nInstall additional Python libraries\n\n\nAlthough the Anaconda Python package include many libraries, there are some specialized libraries required for Soundcast that are not included. Fortunately, these can easily be added from the command prompt. The required additional libraries are:\n\n\n- pysal (used to read geodatabase files from ArcGIS)\n- pandas_highcharts (for visualization of results in iPython notebooks)\n\n\n\nThese can be added either by typing \"pip install [library name]\" or \"conda install [library name]\". If the model run crashes because of a missing library, it should be easy to quickly add the library and restart the model from the point of failure.\n\n\nInstall 7-zip\n\n\nSoundcast inputs are very large and are stored as compressed files to save space. Scripts rely on the 7-zip tool to open and expand these files, and the program \nmust be added to the system path\n. Before running Soundcast, ensure that 7-zip is installed. If not, it can be \nfreely obtained here\n. Once installed, copy the location of the 7-zip.exe and add it to the system's path environment variable. To do this, open the Environment Variables window under Control Panel and edit the \"path\" system variable (the second scroll window from the top).\n\n\nRun Configuration\n\n\nOnce Python paths and versions are defined and installed, inputs must be provided and configuration settings specified. Input locations and run settings are controlled centrally from the file \n\"input_configuration.py\".\n This is a Python script, but it simply holds variable definitions which are passed into other scripts when the model runs. The input configuration contains paths to input directories, scenario names and analysis years, and also controls number of iterations and convergence criteria. Additionally, it allows finer control over specific model components. For instance, all demand, skimming, and assignment iterations can be turned off, and only specific summarization scripts run, or the model can be set to stop after importing certain input files. Scroll to the end of the Variable value field, add paste the directory to the 7zip exe (ensuring it is separated with a semicolon from previous fields).\n\n\nScenarios and input paths are defined as follows by default. Users must point to the location of these inputs and ensure the inputs follow a format as defined later in this guide. \n\n\n- base_year = '2010'  # This should always be 2010 unless the base year changes\n- scenario_name = '2040'\n- daysim_code = 'R:/soundcast/daysim' \n- master_project = 'LoadTripTables'\n- base_inputs = 'R:/soundcast/inputs/' + scenario_name\n- network_buffer_inputs = 'R:/soundcast/inputs/parcel_buffering_network/parcel_buff_network_inputs.7z'\n- network_buffer_code = 'R:/SoundCast/util/parcel_buffering/'\n\n\n\nThe following variables act as control parameters for the model. They are mostly self-explanatory by their variable name. \n\n\n- run_update_parking = False\n- run_convert_hhinc_2000_2010 = False\n- run_parcel_buffering = True\n- run_copy_daysim_code = True\n- run_setup_emme_project_folders = True\n- run_setup_emme_bank_folders = True\n- run_copy_large_inputs = True\n- run_import_networks = True\n- run_skims_and_paths_seed_trips = True\n- should_build_shadow_price =True\n- run_skims_and_paths = True\n- run_truck_model = True\n- run_supplemental_trips = True\n- run_daysim = True\n- run_parcel_buffer_summary = True\n- run_network_summary = True\n- run_soundcast_summary = True\n- run_travel_time_summary = True\n- run_create_daily_bank = True\n\n\n\nFor a basic run, these variables can be left in their default state as stored in the GitHub repository. This applies for all other variables in the input_configuration file, aside from the input directories listed above, which must be defined appropriately by the user.\n\n\nOther important parameters that the user may which to adjust are the number of defined model iterations and population sample settings.\n\n\n- pop_sample = [10, 5, 1, 1, 1, 1]   \n- shadow_work = [1, 1, 1, 1]\n- shadow_con = 10 #%RMSE for shadow pricing to consider being converged\n- STOP_THRESHOLD = 0.025\n- parallel_instances = 12   # Number of simultaneous parallel processes. Must be a factor of 12.\n- max_iter = 50             # Assignment Convergence Criteria\n- best_relative_gap = 0.01  # Assignment Convergence Criteria\n- relative_gap = .0001\n- normalized_gap = 0.01\n\n\n\nThe population sample (pop_sample) is a list of population sample proportions for each iteration to be produced by the DaySim demand models. In the example above, the 10 implies 1/10th of the population will be modeled (to save time for the first pass), and 5 implies 1/5th, whereas 1 represents a full population run. The length of the list represents the number of times the model might be run, if it doesn't first converge.\n\n\nThe \"shadow_work\" variable represents the number of iterations for which shadow pricing will be run. This is an important part of the demand models, but consumes significant run time; the parameter should only be changed with good reason. \n\n\nThe remaining variables in input_configuration are not intended to be changed by the user. Many are definitions that should not change, except with major model revisions. They're stored in this file for consistency, rather than scattering variable definitions across a number of scripts.\n\n\nInputs\n\n\nSoundcast inputs will be provided as a zipped folder to users. However, at this time, inputs will only be available to users with authorized access to use Washington State's highly employment disaggregate data. PSRC is still working through solutions to provide model access to all users without access to this sensitive data. \n\n\nFor users that are able to receive the input, the folder should be unzipped and stored on a local drive. The path must be specified in \"input_configuration.py\" and folder structure should not be changed. Soundcast copies all inputs into the local Soundcast directory to keep paths consistent, and allows for a central storage point of different model inputs. Input folders will typically be named to represent the land use and network year, e.g., 2010 or 2040. \n\n\nThe inputs directory should be structured as follows:\n\n\n- 4k    # inputs for truck model, based on estimates from trip-based 4k model\n    - auto.h5\n    - transit.h5\n- etc\n    - daysim_outputs_seed_trips.h5    # seed trips to use on first iteration of DaySim\n    - survey.h5    # 2006 household travel survey for DaySim estimation validation summaries\n- landuse\n    - buffered_parcels.dat\n    - daily_parking_costs.csv\n    - hh_and_persons.h5\n    - hourly_parking_costs.csv\n    - parcels_military.csv    # Military employment data\n    - parcels_urbansim.txt    # Primary land-use data at the parcel level\n    - schema.ini\n    - tazdata.in\n- networks\n    - am_roadway.in\n    - am_transit.in\n    - am_turns.in\n    ... (roadway, transit, and turns network files for 5 times of day: am, md, pm, ev, ni)\n    - vehicles.txt    # list of transit vehicles and characteristics\n    - modes.txt    # list of modes and their characteristics\n    - fixes\n        - ferries\n            - am_roadway.in\n            ... (roadway ferry flags for 5 times of day: am, md, pm, ev, ni)\n    - rdly\n        - am_rdly.txt\n        ... (rdly.txt for 5 times of day: am, md, pm, ev, ni)\n    - various shapefiles for showing smooth network shapes, rather than blocky network topology. Edges 0-4 correspond to 5 times of day, in order: am, md, pm, ev, ni\n- supplemental\n    - generation\n    - distribution\n    - trips\n- tolls\n    - am_roadway_tolls.in\n    - bridge_ferry_flags.in\n    - ev_roadway_tolls.in\n    - ferry_vehicle_fares.in\n    - md_roadway_tolls.in\n    - ni_roadway_tolls.in\n    - pm_roadway_tolls.in\n- trucks\n    - agshar.in\n    - const.in\n    - districts19_ga.ens\n    - equipshar.in\n    - heavy_trucks_reeb_ee.in\n    - heavy_trucks_reeb_ei.in\n    - heavy_trucks_reeb_ie.in\n    - input_skims.txt\n    - matrix_balancing_spec.txt\n    - matric_calc_spec.txt\n    - minshar.in\n    - prodshar.in\n    - special_gen_heavy_trucks.in\n    - special_gen_light_trucks.in\n    - special_gen_medium_trucks.in\n    - tazdata.in\n    - tcushar.in\n    - truck_gen_calc_dict.txt\n    - truck_matrices_dict.txt\n    - truck_operating_costs.in\n    - whlsshar.in\n\n\n\nRunning the Model\n\n\nOnce the inputs have been properly structured and configuration defined, Soundcast can be started with a single command-line prompt. Open a command prompt and navigate to the location the soundcast directory. In the main directory, type:\n\n\n- python run_soundcast.py\n\n\n\nThis will call the run_soundcast script in Python, which is the master script file to start the model. Depending on the modules specified to run in input_configuration, Soundcast will be spawn its different processes. For a new run, this includes copying inputs into the local Soundcast directory, creating new directories to store outputs, initializing Emme projects, and finally starting an iteration of DaySim demand models and assignment. The model should run until convergence, or until maximum numbers of global iterations are attained, and (if specified) produce summary files and end. \n\n\nLog Files\n\n\nThe Soundcast run can be monitored in the command prompt, since many functions include print statements, but since it takes many hours to complete a run, all important status outputs are stored in log files in the main Soundcast directory. The two primary log files are:\n\n\n- soundcast_log.txt\n- skims_log.txt\n\n\n\nThe soundcast log contains high-level informatino about when different modules of the run began and were completed. Here's an example from the first 2 iterations of a soundcast log:\n\n\n06/02/2015 11:25:39 AM ------------------------NEW RUN STARTING---------------------------------------\n06/02/2015 11:26:11 AM  build_seed_skims starting\n06/02/2015 07:39:14 PM build_seed_skims took 8:13:03.651000\n06/02/2015 07:39:15 PM We're on iteration 0\n\n\n06/02/2015 07:39:15 PM starting run 2015-06-02 19:39:15.084000\n06/02/2015 07:39:15 PM  modify_config starting\n06/02/2015 07:39:15 PM modify_config took 0:00:00\n06/02/2015 07:39:15 PM  daysim_assignment starting\n06/02/2015 07:39:15 PM Start of 0 iteration of Daysim\n06/02/2015 08:28:47 PM End of 0 iteration of Daysim\n06/02/2015 08:47:46 PM Start of 0 iteration of Skims and Paths\n06/03/2015 09:03:20 AM End of 0 iteration of Skims and Paths\n06/03/2015 09:03:20 AM daysim_assignment took 13:24:05.685000\n06/03/2015 09:03:20 AM  check_convergence starting\n06/03/2015 09:03:20 AM check_convergence took 0:00:00\n06/03/2015 09:03:20 AM We're on iteration 1\n\n\n06/03/2015 09:03:20 AM starting run 2015-06-03 09:03:20.784000\n06/03/2015 09:03:20 AM  modify_config starting\n06/03/2015 09:03:20 AM modify_config took 0:00:00\n06/03/2015 09:03:20 AM  daysim_assignment starting\n06/03/2015 09:03:20 AM Start of 1 iteration of Daysim\n06/03/2015 10:33:40 AM End of 1 iteration of Daysim\n06/03/2015 10:40:47 AM Start of 1 iteration of Skims and Paths\n06/03/2015 02:09:30 PM End of 1 iteration of Skims and Paths\n06/03/2015 02:09:30 PM daysim_assignment took 5:06:09.604000\n06/03/2015 02:09:30 PM  check_convergence starting\n06/03/2015 02:09:30 PM check_convergence took 0:00:00.015000\n06/03/2015 02:09:30 PM We're on iteration 2\n\n\n\nThe skims log provides details on when each assignment and skimming script began, how long it took to complete, and the resulting relative gap, for each user class and time of day.\n\n\nModel Structure\n\n\nSoundcast is designed to run its processes in a specific order. Understanding this flow is critical to performing partial runs (e.g., traffic assignment or demand only) that will save processing time. Being able to recover from a crash mid-way through a model run requires knowledge of how the model's scripts are designed. The basic process is as follows.\n\n\nrun_soundcast.py\n\n\nSoundcast's primary controller script is run_soundcast.py. Most of the major model functions are controlled here, along with input_configuration.py, which controls which processes are run, and certain input values. The run_soundcast script is rather readable, with many processes self-documented by relevant function or variable names. As with all Python scripts in Soundcast, the main function of the scripts are contained in the main() function. This is the part of the script that is first executed. In run_soundcast, subprocesses are called in a specific order. Subprocesses are controlled by binary variables that are defined in input_configuration. If these control variables are defined as True in input_configuration, Soundcast will execute that subprocess. For instance, if the variable \"run_copy_daysim_code\" is defined as True in the configuration, then Soundcast will run the function to move all Daysim inputs into the local directory. Many times, if a model run is being run for another iteration, or has been stopped during a crash, these processes will not need to be repeated, so they are frequently turned off (set to False). The order of subprocesses exectued by run_soundcast are as follows:\n\n\n- parcel buffering (land use preparation for demand estimation)\n- parcel buffering summary (a CSV for error checking)\n- copy Daysim code\n- setup emmebank and project folders (for each time of day used in assignment)\n- copy large inputs to local directory\n- update household income to base year (2010) values\n- import networks\n- run all skims and paths (using seed trips for 0th iteration)\n- demand modeling with Daysim\n- assign truck and supplemental (external, special generator) trips\n- run skims and paths using Daysim demand results\n- repeat global demand and assignment for fixed number of iterations\n\n\n\nThe number of global iterations is defined in input_configuration.py, as the length of the pop_sample array. Each value in this list represents an iteration of demand+skimming/assignment. The number corresponds to the population size being sampled on that run. Samples are used to reduce run time, and the sample size should gradually increase with each iteration. The number is actually the denominator of the population size. For instance pop_sample = [10,5,2] indicates that 3 global iterations will be performed. The first will use a population sample size of 1/10th the actual population, the next a sample of 1/5, and finally a sample of 1/2. \n\n\nResults and Outputs\n\n\nAs the model runs, results are stored in the 'outputs' directory of the local soundcast folder. Emme-related outputs are stored in 'projects' and 'banks' folders. Users can view results by time of day by opening up the corresponding project and bank in Emme. These files contain all time and cost skims by vehicle class and time of day. They are also available in a compressed format (hdf5) and, somewhat confusingly, created in the 'inputs' folder after an assignment iteration. They're stored in inputs because they're used as inputs to DaySim demand modeling, though they will represent the last assignment and skimming pass. These output files are named by their time period (e.g., 5to6.h5) and can be viewed interactively with Python or the \nOMX Viewer\n GUI.\n\n\nResults of DaySim demand are stored in hdf5 format as well, in the 'daysim_outputs.h5' file stored in the 'outputs' folder. These outputs include details for all persons, households, trips, and tours taken in the region, for a typical travel day. These include all the details about demographics and trip characteristics like mode, purpose, time, origin and destination, and many others. \n\n\nSoundcast includes Python scripts to summarize model results and create output spreadsheets. The primary summaries are available in the following sheets:\n\n\n- network_summary.xlsx\n- Topsheet.xlsx\n\n\n\nOther summaries are included for detailed DaySim and network summaries as needed. Users may also create their own summaries by directly evaluating the h5 output files.\n\n\nFile Information and Directory Structure\n\n\nResources\n\n\n\n\nActivity-Based Modeling at PSRC\n\n\nSoundcast Technical Design Document\n\n\nSoundcast GitHub Repo\n\n\nAcitivty-Based Model Primer\n\n\nPSRC Staff", 
            "title": "Home"
        }, 
        {
            "location": "/#soundcast-users-guide", 
            "text": "The Soundcast model package includes all estimated and calibrated demand models and scripts to assign demand onto road and transit networks. Soundcast's demand models were developed as part of the DaySim activity model framework by consultants  RSG . As shown in the figure below, the demand models process land use, demographics, and network inputs to produce trip tables by user class and time of day. These trips (i.e., 'demand') are then assigned to travel networks using  INRO's Emme software . If network assignment hasn't yet reached equilibrium, cost and time skims are sent back to the DaySim demand models to produce trip tables that incorporate network conditions from the latest model iteration. Upon convergence (specified as a configurable parameter) the model estimation will conclude and produce summary reports.", 
            "title": "Soundcast Users' Guide"
        }, 
        {
            "location": "/#hardware-recommendations", 
            "text": "- 100 GB disk space for each model run\n- 32 GB RAM recommended\n- Minimum of 12 processors  (Soundcast can be run on machines with less memory and fewer processors, but run time will be extended.)", 
            "title": "Hardware Recommendations"
        }, 
        {
            "location": "/#software-recommendations", 
            "text": "- INRO Emme 4 License, with capability for processing 4000-zone matrices\n- Only tested on 64-bit Windows 7 OS\n- Anaconda Python Package (Python 2.7 with helper libraries included)", 
            "title": "Software Recommendations"
        }, 
        {
            "location": "/#initial-setup", 
            "text": "All Soundcast scripts are stored within a public  GitHub repository . If you're familiar with Git technology, you can  clone  the repository on your modeling machine.   Alternatively, you can download all the code as a ZIP file.    Python Packages and Paths  It's recommended to  install the Anaconda Python package  to run Soundcast. This package should include all necessary libraries to run the model. When installing, make sure the installer adds the Anaconda install to the system path (or add it yourself after installing). It's important that this install is the one referenced whenever the \"python\" program is invoked from a command. Many machines might include another Python install; it's okay to leave other versions installed, but you'll want to update the path variable to point only to the Anaconda version. In order to avoid conflicts with Emme's Python install,  download package version 2.2.0.   Click here to directly download Anaconda 2.2.0 for 64-bit Windows . Additionally, you may want to install Anaconda for current users only (not for all users). Sometimes installing Python for all users will conflict with administrative rights, so it's best to install and use it as a local user.   After installing Anaconda, you must change Emme's settings to use the Anaconda installation by default. Otherwise, scripts that interact with Emme will use another install without the necessary libraries. To change the Python version used by Emme, select Tools (from the main taskbar) and click 'Application Options'. Under the Modeller tab is a field \"Python path\", which by default probably looks like:  % $EmmePath %/Python27   Replace this path with the full path to the Anaconda Python executable (python.exe). Depending on where Anaconda was installed, it may be something like:  C:\\Anaconda  Troubleshooting Python Install  Emme's Python libraries can conflict with the Anaconda install used to run Python. As of Emme release 4.2.3, there are two known conflicts with the Anaconda libraries. Two libraries \"ply\" and \"pyqt\" from Anaconda clash with Emme. INRO's solution is to remove these two libraries from the Anaconda install and rely on the Emme libraries. This works for Anaconda 2.2.0 and prior releases, but does not work for the latest versions. For now, the recommended approach is to use Anaconda 2.2.0 and remove ply and pyqt libraries. This can be done from the command prompt with \"conda uninstall ply\" and \"condat uninstall pyqt\". When these libraries are removed from Anaconda, Emme will look to its local install of these packages, which should have no conflicts.  Install additional Python libraries  Although the Anaconda Python package include many libraries, there are some specialized libraries required for Soundcast that are not included. Fortunately, these can easily be added from the command prompt. The required additional libraries are:  - pysal (used to read geodatabase files from ArcGIS)\n- pandas_highcharts (for visualization of results in iPython notebooks)  These can be added either by typing \"pip install [library name]\" or \"conda install [library name]\". If the model run crashes because of a missing library, it should be easy to quickly add the library and restart the model from the point of failure.  Install 7-zip  Soundcast inputs are very large and are stored as compressed files to save space. Scripts rely on the 7-zip tool to open and expand these files, and the program  must be added to the system path . Before running Soundcast, ensure that 7-zip is installed. If not, it can be  freely obtained here . Once installed, copy the location of the 7-zip.exe and add it to the system's path environment variable. To do this, open the Environment Variables window under Control Panel and edit the \"path\" system variable (the second scroll window from the top).", 
            "title": "Initial Setup"
        }, 
        {
            "location": "/#run-configuration", 
            "text": "Once Python paths and versions are defined and installed, inputs must be provided and configuration settings specified. Input locations and run settings are controlled centrally from the file  \"input_configuration.py\".  This is a Python script, but it simply holds variable definitions which are passed into other scripts when the model runs. The input configuration contains paths to input directories, scenario names and analysis years, and also controls number of iterations and convergence criteria. Additionally, it allows finer control over specific model components. For instance, all demand, skimming, and assignment iterations can be turned off, and only specific summarization scripts run, or the model can be set to stop after importing certain input files. Scroll to the end of the Variable value field, add paste the directory to the 7zip exe (ensuring it is separated with a semicolon from previous fields).  Scenarios and input paths are defined as follows by default. Users must point to the location of these inputs and ensure the inputs follow a format as defined later in this guide.   - base_year = '2010'  # This should always be 2010 unless the base year changes\n- scenario_name = '2040'\n- daysim_code = 'R:/soundcast/daysim' \n- master_project = 'LoadTripTables'\n- base_inputs = 'R:/soundcast/inputs/' + scenario_name\n- network_buffer_inputs = 'R:/soundcast/inputs/parcel_buffering_network/parcel_buff_network_inputs.7z'\n- network_buffer_code = 'R:/SoundCast/util/parcel_buffering/'  The following variables act as control parameters for the model. They are mostly self-explanatory by their variable name.   - run_update_parking = False\n- run_convert_hhinc_2000_2010 = False\n- run_parcel_buffering = True\n- run_copy_daysim_code = True\n- run_setup_emme_project_folders = True\n- run_setup_emme_bank_folders = True\n- run_copy_large_inputs = True\n- run_import_networks = True\n- run_skims_and_paths_seed_trips = True\n- should_build_shadow_price =True\n- run_skims_and_paths = True\n- run_truck_model = True\n- run_supplemental_trips = True\n- run_daysim = True\n- run_parcel_buffer_summary = True\n- run_network_summary = True\n- run_soundcast_summary = True\n- run_travel_time_summary = True\n- run_create_daily_bank = True  For a basic run, these variables can be left in their default state as stored in the GitHub repository. This applies for all other variables in the input_configuration file, aside from the input directories listed above, which must be defined appropriately by the user.  Other important parameters that the user may which to adjust are the number of defined model iterations and population sample settings.  - pop_sample = [10, 5, 1, 1, 1, 1]   \n- shadow_work = [1, 1, 1, 1]\n- shadow_con = 10 #%RMSE for shadow pricing to consider being converged\n- STOP_THRESHOLD = 0.025\n- parallel_instances = 12   # Number of simultaneous parallel processes. Must be a factor of 12.\n- max_iter = 50             # Assignment Convergence Criteria\n- best_relative_gap = 0.01  # Assignment Convergence Criteria\n- relative_gap = .0001\n- normalized_gap = 0.01  The population sample (pop_sample) is a list of population sample proportions for each iteration to be produced by the DaySim demand models. In the example above, the 10 implies 1/10th of the population will be modeled (to save time for the first pass), and 5 implies 1/5th, whereas 1 represents a full population run. The length of the list represents the number of times the model might be run, if it doesn't first converge.  The \"shadow_work\" variable represents the number of iterations for which shadow pricing will be run. This is an important part of the demand models, but consumes significant run time; the parameter should only be changed with good reason.   The remaining variables in input_configuration are not intended to be changed by the user. Many are definitions that should not change, except with major model revisions. They're stored in this file for consistency, rather than scattering variable definitions across a number of scripts.", 
            "title": "Run Configuration"
        }, 
        {
            "location": "/#inputs", 
            "text": "Soundcast inputs will be provided as a zipped folder to users. However, at this time, inputs will only be available to users with authorized access to use Washington State's highly employment disaggregate data. PSRC is still working through solutions to provide model access to all users without access to this sensitive data.   For users that are able to receive the input, the folder should be unzipped and stored on a local drive. The path must be specified in \"input_configuration.py\" and folder structure should not be changed. Soundcast copies all inputs into the local Soundcast directory to keep paths consistent, and allows for a central storage point of different model inputs. Input folders will typically be named to represent the land use and network year, e.g., 2010 or 2040.   The inputs directory should be structured as follows:  - 4k    # inputs for truck model, based on estimates from trip-based 4k model\n    - auto.h5\n    - transit.h5\n- etc\n    - daysim_outputs_seed_trips.h5    # seed trips to use on first iteration of DaySim\n    - survey.h5    # 2006 household travel survey for DaySim estimation validation summaries\n- landuse\n    - buffered_parcels.dat\n    - daily_parking_costs.csv\n    - hh_and_persons.h5\n    - hourly_parking_costs.csv\n    - parcels_military.csv    # Military employment data\n    - parcels_urbansim.txt    # Primary land-use data at the parcel level\n    - schema.ini\n    - tazdata.in\n- networks\n    - am_roadway.in\n    - am_transit.in\n    - am_turns.in\n    ... (roadway, transit, and turns network files for 5 times of day: am, md, pm, ev, ni)\n    - vehicles.txt    # list of transit vehicles and characteristics\n    - modes.txt    # list of modes and their characteristics\n    - fixes\n        - ferries\n            - am_roadway.in\n            ... (roadway ferry flags for 5 times of day: am, md, pm, ev, ni)\n    - rdly\n        - am_rdly.txt\n        ... (rdly.txt for 5 times of day: am, md, pm, ev, ni)\n    - various shapefiles for showing smooth network shapes, rather than blocky network topology. Edges 0-4 correspond to 5 times of day, in order: am, md, pm, ev, ni\n- supplemental\n    - generation\n    - distribution\n    - trips\n- tolls\n    - am_roadway_tolls.in\n    - bridge_ferry_flags.in\n    - ev_roadway_tolls.in\n    - ferry_vehicle_fares.in\n    - md_roadway_tolls.in\n    - ni_roadway_tolls.in\n    - pm_roadway_tolls.in\n- trucks\n    - agshar.in\n    - const.in\n    - districts19_ga.ens\n    - equipshar.in\n    - heavy_trucks_reeb_ee.in\n    - heavy_trucks_reeb_ei.in\n    - heavy_trucks_reeb_ie.in\n    - input_skims.txt\n    - matrix_balancing_spec.txt\n    - matric_calc_spec.txt\n    - minshar.in\n    - prodshar.in\n    - special_gen_heavy_trucks.in\n    - special_gen_light_trucks.in\n    - special_gen_medium_trucks.in\n    - tazdata.in\n    - tcushar.in\n    - truck_gen_calc_dict.txt\n    - truck_matrices_dict.txt\n    - truck_operating_costs.in\n    - whlsshar.in", 
            "title": "Inputs"
        }, 
        {
            "location": "/#running-the-model", 
            "text": "Once the inputs have been properly structured and configuration defined, Soundcast can be started with a single command-line prompt. Open a command prompt and navigate to the location the soundcast directory. In the main directory, type:  - python run_soundcast.py  This will call the run_soundcast script in Python, which is the master script file to start the model. Depending on the modules specified to run in input_configuration, Soundcast will be spawn its different processes. For a new run, this includes copying inputs into the local Soundcast directory, creating new directories to store outputs, initializing Emme projects, and finally starting an iteration of DaySim demand models and assignment. The model should run until convergence, or until maximum numbers of global iterations are attained, and (if specified) produce summary files and end.", 
            "title": "Running the Model"
        }, 
        {
            "location": "/#log-files", 
            "text": "The Soundcast run can be monitored in the command prompt, since many functions include print statements, but since it takes many hours to complete a run, all important status outputs are stored in log files in the main Soundcast directory. The two primary log files are:  - soundcast_log.txt\n- skims_log.txt  The soundcast log contains high-level informatino about when different modules of the run began and were completed. Here's an example from the first 2 iterations of a soundcast log:  06/02/2015 11:25:39 AM ------------------------NEW RUN STARTING---------------------------------------\n06/02/2015 11:26:11 AM  build_seed_skims starting\n06/02/2015 07:39:14 PM build_seed_skims took 8:13:03.651000\n06/02/2015 07:39:15 PM We're on iteration 0\n\n\n06/02/2015 07:39:15 PM starting run 2015-06-02 19:39:15.084000\n06/02/2015 07:39:15 PM  modify_config starting\n06/02/2015 07:39:15 PM modify_config took 0:00:00\n06/02/2015 07:39:15 PM  daysim_assignment starting\n06/02/2015 07:39:15 PM Start of 0 iteration of Daysim\n06/02/2015 08:28:47 PM End of 0 iteration of Daysim\n06/02/2015 08:47:46 PM Start of 0 iteration of Skims and Paths\n06/03/2015 09:03:20 AM End of 0 iteration of Skims and Paths\n06/03/2015 09:03:20 AM daysim_assignment took 13:24:05.685000\n06/03/2015 09:03:20 AM  check_convergence starting\n06/03/2015 09:03:20 AM check_convergence took 0:00:00\n06/03/2015 09:03:20 AM We're on iteration 1\n\n\n06/03/2015 09:03:20 AM starting run 2015-06-03 09:03:20.784000\n06/03/2015 09:03:20 AM  modify_config starting\n06/03/2015 09:03:20 AM modify_config took 0:00:00\n06/03/2015 09:03:20 AM  daysim_assignment starting\n06/03/2015 09:03:20 AM Start of 1 iteration of Daysim\n06/03/2015 10:33:40 AM End of 1 iteration of Daysim\n06/03/2015 10:40:47 AM Start of 1 iteration of Skims and Paths\n06/03/2015 02:09:30 PM End of 1 iteration of Skims and Paths\n06/03/2015 02:09:30 PM daysim_assignment took 5:06:09.604000\n06/03/2015 02:09:30 PM  check_convergence starting\n06/03/2015 02:09:30 PM check_convergence took 0:00:00.015000\n06/03/2015 02:09:30 PM We're on iteration 2  The skims log provides details on when each assignment and skimming script began, how long it took to complete, and the resulting relative gap, for each user class and time of day.", 
            "title": "Log Files"
        }, 
        {
            "location": "/#model-structure", 
            "text": "Soundcast is designed to run its processes in a specific order. Understanding this flow is critical to performing partial runs (e.g., traffic assignment or demand only) that will save processing time. Being able to recover from a crash mid-way through a model run requires knowledge of how the model's scripts are designed. The basic process is as follows.  run_soundcast.py  Soundcast's primary controller script is run_soundcast.py. Most of the major model functions are controlled here, along with input_configuration.py, which controls which processes are run, and certain input values. The run_soundcast script is rather readable, with many processes self-documented by relevant function or variable names. As with all Python scripts in Soundcast, the main function of the scripts are contained in the main() function. This is the part of the script that is first executed. In run_soundcast, subprocesses are called in a specific order. Subprocesses are controlled by binary variables that are defined in input_configuration. If these control variables are defined as True in input_configuration, Soundcast will execute that subprocess. For instance, if the variable \"run_copy_daysim_code\" is defined as True in the configuration, then Soundcast will run the function to move all Daysim inputs into the local directory. Many times, if a model run is being run for another iteration, or has been stopped during a crash, these processes will not need to be repeated, so they are frequently turned off (set to False). The order of subprocesses exectued by run_soundcast are as follows:  - parcel buffering (land use preparation for demand estimation)\n- parcel buffering summary (a CSV for error checking)\n- copy Daysim code\n- setup emmebank and project folders (for each time of day used in assignment)\n- copy large inputs to local directory\n- update household income to base year (2010) values\n- import networks\n- run all skims and paths (using seed trips for 0th iteration)\n- demand modeling with Daysim\n- assign truck and supplemental (external, special generator) trips\n- run skims and paths using Daysim demand results\n- repeat global demand and assignment for fixed number of iterations  The number of global iterations is defined in input_configuration.py, as the length of the pop_sample array. Each value in this list represents an iteration of demand+skimming/assignment. The number corresponds to the population size being sampled on that run. Samples are used to reduce run time, and the sample size should gradually increase with each iteration. The number is actually the denominator of the population size. For instance pop_sample = [10,5,2] indicates that 3 global iterations will be performed. The first will use a population sample size of 1/10th the actual population, the next a sample of 1/5, and finally a sample of 1/2.", 
            "title": "Model Structure"
        }, 
        {
            "location": "/#results-and-outputs", 
            "text": "As the model runs, results are stored in the 'outputs' directory of the local soundcast folder. Emme-related outputs are stored in 'projects' and 'banks' folders. Users can view results by time of day by opening up the corresponding project and bank in Emme. These files contain all time and cost skims by vehicle class and time of day. They are also available in a compressed format (hdf5) and, somewhat confusingly, created in the 'inputs' folder after an assignment iteration. They're stored in inputs because they're used as inputs to DaySim demand modeling, though they will represent the last assignment and skimming pass. These output files are named by their time period (e.g., 5to6.h5) and can be viewed interactively with Python or the  OMX Viewer  GUI.  Results of DaySim demand are stored in hdf5 format as well, in the 'daysim_outputs.h5' file stored in the 'outputs' folder. These outputs include details for all persons, households, trips, and tours taken in the region, for a typical travel day. These include all the details about demographics and trip characteristics like mode, purpose, time, origin and destination, and many others.   Soundcast includes Python scripts to summarize model results and create output spreadsheets. The primary summaries are available in the following sheets:  - network_summary.xlsx\n- Topsheet.xlsx  Other summaries are included for detailed DaySim and network summaries as needed. Users may also create their own summaries by directly evaluating the h5 output files.  File Information and Directory Structure", 
            "title": "Results and Outputs"
        }, 
        {
            "location": "/#resources", 
            "text": "Activity-Based Modeling at PSRC  Soundcast Technical Design Document  Soundcast GitHub Repo  Acitivty-Based Model Primer  PSRC Staff", 
            "title": "Resources"
        }, 
        {
            "location": "/file-structure/", 
            "text": "file-structure\n\n\nSoundCast File and Directory Structure\n\n\nInputs\n\n\nSoundcast inputs will be provided as a zipped folder to users. However, at this time, inputs will only be available to users with authorized access to use Washington State's highly employment disaggregate data. PSRC is still working through solutions to provide model access to all users without access to this sensitive data. \n\n\nFor users that are able to receive the input, the folder should be unzipped and stored on a local drive. The path must be specified in \"input_configuration.py\" and folder structure should not be changed. Soundcast copies all inputs into the local Soundcast directory to keep paths consistent, and allows for a central storage point of different model inputs. Input folders will typically be named to represent the land use and network year, e.g., 2010 or 2040. \n\n\nThe inputs directory should be structured as follows:\n\n\n- 4k    # inputs for truck model, based on estimates from trip-based 4k model\n    - auto.h5\n    - transit.h5\n- etc\n    - daysim_outputs_seed_trips.h5    # seed trips to use on first iteration of DaySim\n    - survey.h5    # 2006 household travel survey for DaySim estimation validation summaries\n- landuse\n    - buffered_parcels.dat\n    - daily_parking_costs.csv\n    - hh_and_persons.h5\n    - hourly_parking_costs.csv\n    - parcels_military.csv    # Military employment data\n    - parcels_urbansim.txt    # Primary land-use data at the parcel level\n    - schema.ini\n    - tazdata.in\n- networks\n    - am_roadway.in\n    - am_transit.in\n    - am_turns.in\n    ... (roadway, transit, and turns network files for 5 times of day: am, md, pm, ev, ni)\n    - vehicles.txt    # list of transit vehicles and characteristics\n    - modes.txt    # list of modes and their characteristics\n    - fixes\n        - ferries\n            - am_roadway.in\n            ... (roadway ferry flags for 5 times of day: am, md, pm, ev, ni)\n    - rdly\n        - am_rdly.txt\n        ... (rdly.txt for 5 times of day: am, md, pm, ev, ni)\n    - various shapefiles for showing smooth network shapes, rather than blocky network topology. Edges 0-4 correspond to 5 times of day, in order: am, md, pm, ev, ni\n- supplemental\n    - generation\n    - distribution\n    - trips\n- tolls\n    - am_roadway_tolls.in\n    - bridge_ferry_flags.in\n    - ev_roadway_tolls.in\n    - ferry_vehicle_fares.in\n    - md_roadway_tolls.in\n    - ni_roadway_tolls.in\n    - pm_roadway_tolls.in\n- trucks\n    - agshar.in\n    - const.in\n    - districts19_ga.ens\n    - equipshar.in\n    - heavy_trucks_reeb_ee.in\n    - heavy_trucks_reeb_ei.in\n    - heavy_trucks_reeb_ie.in\n    - input_skims.txt\n    - matrix_balancing_spec.txt\n    - matric_calc_spec.txt\n    - minshar.in\n    - prodshar.in\n    - special_gen_heavy_trucks.in\n    - special_gen_light_trucks.in\n    - special_gen_medium_trucks.in\n    - tazdata.in\n    - tcushar.in\n    - truck_gen_calc_dict.txt\n    - truck_matrices_dict.txt\n    - truck_operating_costs.in\n    - whlsshar.in\n\n\n\nRunning the Model\n\n\nOnce the inputs have been properly structured and configuration defined, Soundcast can be started with a single command-line prompt. Open a command prompt and navigate to the location the soundcast directory. In the main directory, type:\n\n\n- python run_soundcast.py\n\n\n\nThis will call the run_soundcast script in Python, which is the master script file to start the model. Depending on the modules specified to run in input_configuration, Soundcast will be spawn its different processes. For a new run, this includes copying inputs into the local Soundcast directory, creating new directories to store outputs, initializing Emme projects, and finally starting an iteration of DaySim demand models and assignment. The model should run until convergence, or until maximum numbers of global iterations are attained, and (if specified) produce summary files and end. \n\n\nLog Files\n\n\nThe Soundcast run can be monitored in the command prompt, since many functions include print statements, but since it takes many hours to complete a run, all important status outputs are stored in log files in the main Soundcast directory. The two primary log files are:\n\n\n- soundcast_log.txt\n- skims_log.txt\n\n\n\nThe soundcast log contains high-level informatino about when different modules of the run began and were completed. Here's an example from the first 2 iterations of a soundcast log:\n\n\n06/02/2015 11:25:39 AM ------------------------NEW RUN STARTING---------------------------------------\n06/02/2015 11:26:11 AM  build_seed_skims starting\n06/02/2015 07:39:14 PM build_seed_skims took 8:13:03.651000\n06/02/2015 07:39:15 PM We're on iteration 0\n\n\n06/02/2015 07:39:15 PM starting run 2015-06-02 19:39:15.084000\n06/02/2015 07:39:15 PM  modify_config starting\n06/02/2015 07:39:15 PM modify_config took 0:00:00\n06/02/2015 07:39:15 PM  daysim_assignment starting\n06/02/2015 07:39:15 PM Start of 0 iteration of Daysim\n06/02/2015 08:28:47 PM End of 0 iteration of Daysim\n06/02/2015 08:47:46 PM Start of 0 iteration of Skims and Paths\n06/03/2015 09:03:20 AM End of 0 iteration of Skims and Paths\n06/03/2015 09:03:20 AM daysim_assignment took 13:24:05.685000\n06/03/2015 09:03:20 AM  check_convergence starting\n06/03/2015 09:03:20 AM check_convergence took 0:00:00\n06/03/2015 09:03:20 AM We're on iteration 1\n\n\n06/03/2015 09:03:20 AM starting run 2015-06-03 09:03:20.784000\n06/03/2015 09:03:20 AM  modify_config starting\n06/03/2015 09:03:20 AM modify_config took 0:00:00\n06/03/2015 09:03:20 AM  daysim_assignment starting\n06/03/2015 09:03:20 AM Start of 1 iteration of Daysim\n06/03/2015 10:33:40 AM End of 1 iteration of Daysim\n06/03/2015 10:40:47 AM Start of 1 iteration of Skims and Paths\n06/03/2015 02:09:30 PM End of 1 iteration of Skims and Paths\n06/03/2015 02:09:30 PM daysim_assignment took 5:06:09.604000\n06/03/2015 02:09:30 PM  check_convergence starting\n06/03/2015 02:09:30 PM check_convergence took 0:00:00.015000\n06/03/2015 02:09:30 PM We're on iteration 2\n\n\n\nThe skims log provides details on when each assignment and skimming script began, how long it took to complete, and the resulting relative gap, for each user class and time of day.\n\n\nModel Structure\n\n\nSoundcast is designed to run its processes in a specific order. Understanding this flow is critical to performing partial runs (e.g., traffic assignment or demand only) that will save processing time. Being able to recover from a crash mid-way through a model run requires knowledge of how the model's scripts are designed. The basic process is as follows.\n\n\nrun_soundcast.py\n\n\nSoundcast's primary controller script is run_soundcast.py. Most of the major model functions are controlled here, along with input_configuration.py, which controls which processes are run, and certain input values. The run_soundcast script is rather readable, with many processes self-documented by relevant function or variable names. As with all Python scripts in Soundcast, the main function of the scripts are contained in the main() function. This is the part of the script that is first executed. In run_soundcast, subprocesses are called in a specific order. Subprocesses are controlled by binary variables that are defined in input_configuration. If these control variables are defined as True in input_configuration, Soundcast will execute that subprocess. For instance, if the variable \"run_copy_daysim_code\" is defined as True in the configuration, then Soundcast will run the function to move all Daysim inputs into the local directory. Many times, if a model run is being run for another iteration, or has been stopped during a crash, these processes will not need to be repeated, so they are frequently turned off (set to False). The order of subprocesses exectued by run_soundcast are as follows:\n\n\n- parcel buffering (land use preparation for demand estimation)\n- parcel buffering summary (a CSV for error checking)\n- copy Daysim code\n- setup emmebank and project folders (for each time of day used in assignment)\n- copy large inputs to local directory\n- update household income to base year (2010) values\n- import networks\n- run all skims and paths (using seed trips for 0th iteration)\n- demand modeling with Daysim\n- assign truck and supplemental (external, special generator) trips\n- run skims and paths using Daysim demand results\n- repeat global demand and assignment for fixed number of iterations\n\n\n\nThe number of global iterations is defined in input_configuration.py, as the length of the pop_sample array. Each value in this list represents an iteration of demand+skimming/assignment. The number corresponds to the population size being sampled on that run. Samples are used to reduce run time, and the sample size should gradually increase with each iteration. The number is actually the denominator of the population size. For instance pop_sample = [10,5,2] indicates that 3 global iterations will be performed. The first will use a population sample size of 1/10th the actual population, the next a sample of 1/5, and finally a sample of 1/2. \n\n\nResults and Outputs\n\n\nAs the model runs, results are stored in the 'outputs' directory of the local soundcast folder. Emme-related outputs are stored in 'projects' and 'banks' folders. Users can view results by time of day by opening up the corresponding project and bank in Emme. These files contain all time and cost skims by vehicle class and time of day. They are also available in a compressed format (hdf5) and, somewhat confusingly, created in the 'inputs' folder after an assignment iteration. They're stored in inputs because they're used as inputs to DaySim demand modeling, though they will represent the last assignment and skimming pass. These output files are named by their time period (e.g., 5to6.h5) and can be viewed interactively with Python or the \nOMX Viewer\n GUI.\n\n\nResults of DaySim demand are stored in hdf5 format as well, in the 'daysim_outputs.h5' file stored in the 'outputs' folder. These outputs include details for all persons, households, trips, and tours taken in the region, for a typical travel day. These include all the details about demographics and trip characteristics like mode, purpose, time, origin and destination, and many others. \n\n\nSoundcast includes Python scripts to summarize model results and create output spreadsheets. The primary summaries are available in the following sheets:\n\n\n- network_summary.xlsx\n- Topsheet.xlsx\n\n\n\nOther summaries are included for detailed DaySim and network summaries as needed. Users may also create their own summaries by directly evaluating the h5 output files.\n\n\n[[File Information and Directory Structure]]\n\n\nResources\n\n\n\n\nActivity-Based Modeling at PSRC\n\n\nSoundcast Technical Design Document\n\n\nSoundcast GitHub Repo\n\n\nAcitivty-Based Model Primer\n\n\nPSRC Staff", 
            "title": "FileStructure"
        }, 
        {
            "location": "/file-structure/#soundcast-file-and-directory-structure", 
            "text": "", 
            "title": "SoundCast File and Directory Structure"
        }, 
        {
            "location": "/file-structure/#inputs", 
            "text": "Soundcast inputs will be provided as a zipped folder to users. However, at this time, inputs will only be available to users with authorized access to use Washington State's highly employment disaggregate data. PSRC is still working through solutions to provide model access to all users without access to this sensitive data.   For users that are able to receive the input, the folder should be unzipped and stored on a local drive. The path must be specified in \"input_configuration.py\" and folder structure should not be changed. Soundcast copies all inputs into the local Soundcast directory to keep paths consistent, and allows for a central storage point of different model inputs. Input folders will typically be named to represent the land use and network year, e.g., 2010 or 2040.   The inputs directory should be structured as follows:  - 4k    # inputs for truck model, based on estimates from trip-based 4k model\n    - auto.h5\n    - transit.h5\n- etc\n    - daysim_outputs_seed_trips.h5    # seed trips to use on first iteration of DaySim\n    - survey.h5    # 2006 household travel survey for DaySim estimation validation summaries\n- landuse\n    - buffered_parcels.dat\n    - daily_parking_costs.csv\n    - hh_and_persons.h5\n    - hourly_parking_costs.csv\n    - parcels_military.csv    # Military employment data\n    - parcels_urbansim.txt    # Primary land-use data at the parcel level\n    - schema.ini\n    - tazdata.in\n- networks\n    - am_roadway.in\n    - am_transit.in\n    - am_turns.in\n    ... (roadway, transit, and turns network files for 5 times of day: am, md, pm, ev, ni)\n    - vehicles.txt    # list of transit vehicles and characteristics\n    - modes.txt    # list of modes and their characteristics\n    - fixes\n        - ferries\n            - am_roadway.in\n            ... (roadway ferry flags for 5 times of day: am, md, pm, ev, ni)\n    - rdly\n        - am_rdly.txt\n        ... (rdly.txt for 5 times of day: am, md, pm, ev, ni)\n    - various shapefiles for showing smooth network shapes, rather than blocky network topology. Edges 0-4 correspond to 5 times of day, in order: am, md, pm, ev, ni\n- supplemental\n    - generation\n    - distribution\n    - trips\n- tolls\n    - am_roadway_tolls.in\n    - bridge_ferry_flags.in\n    - ev_roadway_tolls.in\n    - ferry_vehicle_fares.in\n    - md_roadway_tolls.in\n    - ni_roadway_tolls.in\n    - pm_roadway_tolls.in\n- trucks\n    - agshar.in\n    - const.in\n    - districts19_ga.ens\n    - equipshar.in\n    - heavy_trucks_reeb_ee.in\n    - heavy_trucks_reeb_ei.in\n    - heavy_trucks_reeb_ie.in\n    - input_skims.txt\n    - matrix_balancing_spec.txt\n    - matric_calc_spec.txt\n    - minshar.in\n    - prodshar.in\n    - special_gen_heavy_trucks.in\n    - special_gen_light_trucks.in\n    - special_gen_medium_trucks.in\n    - tazdata.in\n    - tcushar.in\n    - truck_gen_calc_dict.txt\n    - truck_matrices_dict.txt\n    - truck_operating_costs.in\n    - whlsshar.in", 
            "title": "Inputs"
        }, 
        {
            "location": "/file-structure/#running-the-model", 
            "text": "Once the inputs have been properly structured and configuration defined, Soundcast can be started with a single command-line prompt. Open a command prompt and navigate to the location the soundcast directory. In the main directory, type:  - python run_soundcast.py  This will call the run_soundcast script in Python, which is the master script file to start the model. Depending on the modules specified to run in input_configuration, Soundcast will be spawn its different processes. For a new run, this includes copying inputs into the local Soundcast directory, creating new directories to store outputs, initializing Emme projects, and finally starting an iteration of DaySim demand models and assignment. The model should run until convergence, or until maximum numbers of global iterations are attained, and (if specified) produce summary files and end.", 
            "title": "Running the Model"
        }, 
        {
            "location": "/file-structure/#log-files", 
            "text": "The Soundcast run can be monitored in the command prompt, since many functions include print statements, but since it takes many hours to complete a run, all important status outputs are stored in log files in the main Soundcast directory. The two primary log files are:  - soundcast_log.txt\n- skims_log.txt  The soundcast log contains high-level informatino about when different modules of the run began and were completed. Here's an example from the first 2 iterations of a soundcast log:  06/02/2015 11:25:39 AM ------------------------NEW RUN STARTING---------------------------------------\n06/02/2015 11:26:11 AM  build_seed_skims starting\n06/02/2015 07:39:14 PM build_seed_skims took 8:13:03.651000\n06/02/2015 07:39:15 PM We're on iteration 0\n\n\n06/02/2015 07:39:15 PM starting run 2015-06-02 19:39:15.084000\n06/02/2015 07:39:15 PM  modify_config starting\n06/02/2015 07:39:15 PM modify_config took 0:00:00\n06/02/2015 07:39:15 PM  daysim_assignment starting\n06/02/2015 07:39:15 PM Start of 0 iteration of Daysim\n06/02/2015 08:28:47 PM End of 0 iteration of Daysim\n06/02/2015 08:47:46 PM Start of 0 iteration of Skims and Paths\n06/03/2015 09:03:20 AM End of 0 iteration of Skims and Paths\n06/03/2015 09:03:20 AM daysim_assignment took 13:24:05.685000\n06/03/2015 09:03:20 AM  check_convergence starting\n06/03/2015 09:03:20 AM check_convergence took 0:00:00\n06/03/2015 09:03:20 AM We're on iteration 1\n\n\n06/03/2015 09:03:20 AM starting run 2015-06-03 09:03:20.784000\n06/03/2015 09:03:20 AM  modify_config starting\n06/03/2015 09:03:20 AM modify_config took 0:00:00\n06/03/2015 09:03:20 AM  daysim_assignment starting\n06/03/2015 09:03:20 AM Start of 1 iteration of Daysim\n06/03/2015 10:33:40 AM End of 1 iteration of Daysim\n06/03/2015 10:40:47 AM Start of 1 iteration of Skims and Paths\n06/03/2015 02:09:30 PM End of 1 iteration of Skims and Paths\n06/03/2015 02:09:30 PM daysim_assignment took 5:06:09.604000\n06/03/2015 02:09:30 PM  check_convergence starting\n06/03/2015 02:09:30 PM check_convergence took 0:00:00.015000\n06/03/2015 02:09:30 PM We're on iteration 2  The skims log provides details on when each assignment and skimming script began, how long it took to complete, and the resulting relative gap, for each user class and time of day.", 
            "title": "Log Files"
        }, 
        {
            "location": "/file-structure/#model-structure", 
            "text": "Soundcast is designed to run its processes in a specific order. Understanding this flow is critical to performing partial runs (e.g., traffic assignment or demand only) that will save processing time. Being able to recover from a crash mid-way through a model run requires knowledge of how the model's scripts are designed. The basic process is as follows.  run_soundcast.py  Soundcast's primary controller script is run_soundcast.py. Most of the major model functions are controlled here, along with input_configuration.py, which controls which processes are run, and certain input values. The run_soundcast script is rather readable, with many processes self-documented by relevant function or variable names. As with all Python scripts in Soundcast, the main function of the scripts are contained in the main() function. This is the part of the script that is first executed. In run_soundcast, subprocesses are called in a specific order. Subprocesses are controlled by binary variables that are defined in input_configuration. If these control variables are defined as True in input_configuration, Soundcast will execute that subprocess. For instance, if the variable \"run_copy_daysim_code\" is defined as True in the configuration, then Soundcast will run the function to move all Daysim inputs into the local directory. Many times, if a model run is being run for another iteration, or has been stopped during a crash, these processes will not need to be repeated, so they are frequently turned off (set to False). The order of subprocesses exectued by run_soundcast are as follows:  - parcel buffering (land use preparation for demand estimation)\n- parcel buffering summary (a CSV for error checking)\n- copy Daysim code\n- setup emmebank and project folders (for each time of day used in assignment)\n- copy large inputs to local directory\n- update household income to base year (2010) values\n- import networks\n- run all skims and paths (using seed trips for 0th iteration)\n- demand modeling with Daysim\n- assign truck and supplemental (external, special generator) trips\n- run skims and paths using Daysim demand results\n- repeat global demand and assignment for fixed number of iterations  The number of global iterations is defined in input_configuration.py, as the length of the pop_sample array. Each value in this list represents an iteration of demand+skimming/assignment. The number corresponds to the population size being sampled on that run. Samples are used to reduce run time, and the sample size should gradually increase with each iteration. The number is actually the denominator of the population size. For instance pop_sample = [10,5,2] indicates that 3 global iterations will be performed. The first will use a population sample size of 1/10th the actual population, the next a sample of 1/5, and finally a sample of 1/2.", 
            "title": "Model Structure"
        }, 
        {
            "location": "/file-structure/#results-and-outputs", 
            "text": "As the model runs, results are stored in the 'outputs' directory of the local soundcast folder. Emme-related outputs are stored in 'projects' and 'banks' folders. Users can view results by time of day by opening up the corresponding project and bank in Emme. These files contain all time and cost skims by vehicle class and time of day. They are also available in a compressed format (hdf5) and, somewhat confusingly, created in the 'inputs' folder after an assignment iteration. They're stored in inputs because they're used as inputs to DaySim demand modeling, though they will represent the last assignment and skimming pass. These output files are named by their time period (e.g., 5to6.h5) and can be viewed interactively with Python or the  OMX Viewer  GUI.  Results of DaySim demand are stored in hdf5 format as well, in the 'daysim_outputs.h5' file stored in the 'outputs' folder. These outputs include details for all persons, households, trips, and tours taken in the region, for a typical travel day. These include all the details about demographics and trip characteristics like mode, purpose, time, origin and destination, and many others.   Soundcast includes Python scripts to summarize model results and create output spreadsheets. The primary summaries are available in the following sheets:  - network_summary.xlsx\n- Topsheet.xlsx  Other summaries are included for detailed DaySim and network summaries as needed. Users may also create their own summaries by directly evaluating the h5 output files.  [[File Information and Directory Structure]]", 
            "title": "Results and Outputs"
        }, 
        {
            "location": "/file-structure/#resources", 
            "text": "Activity-Based Modeling at PSRC  Soundcast Technical Design Document  Soundcast GitHub Repo  Acitivty-Based Model Primer  PSRC Staff", 
            "title": "Resources"
        }
    ]
}