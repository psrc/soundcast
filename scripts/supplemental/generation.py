import json
import numpy as np
import pandas as pd
import os,sys
import h5py
import sqlite3
from sqlalchemy import create_engine
sys.path.append(os.path.join(os.getcwd(),"scripts"))
sys.path.append(os.path.join(os.getcwd(),"scripts/trucks"))
sys.path.append(os.getcwd())
# from emme_configuration import *
from EmmeProject import *
import toml
emme_config = toml.load(os.path.join(os.getcwd(), 'configuration/emme_configuration.toml'))

def balance_trips(df, trip_purposes, balanced_to):
    """ Balance trips to productions or attractions."""
    if balanced_to == 'pro':
        to_balance = 'att'
        
    else:
        to_balance = 'pro'
        
    for purposes in trip_purposes:
        total_to_match = sum(df[purposes+balanced_to])
        total_to_balance = sum(df[purposes+to_balance])
        ratio = total_to_match / total_to_balance
        df[purposes+to_balance] = df[purposes+to_balance] * ratio
    
    return df

def create_df_from_h5(h5_file, h5_table, h5_variables):

    h5_data = {}
    for var in h5_variables:
        h5_data[var] = h5_file[h5_table][var][:]
    
    return pd.DataFrame(h5_data)

def calc_heavy_truck_restrictions():
    '''Restrict truck trips by land use type.'''

    #  Load land use type from parcels and a lookup for landuse type codes
    parcels = pd.read_csv(r'outputs/landuse/buffered_parcels.txt', delim_whitespace=True)
    df = parcels.merge(pd.read_csv(r'inputs/model/lookup/lu_type.csv'),left_on='lutype_p',right_on='land_use_type_id')

    # The following list of land use types are allowed to be accessed by heavy trucks
    truck_uses = ['agriculture','forest','industrial','military','mining','warehousing']

    truck_df = df[df['land_use_name'].isin(truck_uses)]
    truck_df['taz_p'].value_counts().index.values
    allowed_tazs = truck_df['taz_p'].value_counts().index.values

    return allowed_tazs

def main():
    print("Calculating supplemental trips generated by exterals, special generators, and group quarters.")

    # Store these in a config:
    trip_productions = ['hbw1pro','hbw2pro','hbw3pro','hbw4pro','colpro','hsppro','hbopro','schpro','otopro','wtopro']
    trip_attractions = ['hbw1att','hbw2att','hbw3att','hbw4att','colatt','hspatt','hboatt','schatt','otoatt','wtoatt']

    # List of columns that should be balanced to productions or attractions
    balance_to_productions = ['hbw1','hbw2','hbw3','hbw4','hsp','hbo','oto','wto','mtk','htk','cvh','dtk']
    balance_to_attractions = ['col','sch']

    # Growth Rates to use for adjsuting input files for specific forecast years
    # Some of these should be calculated and logged in the model directly
    special_generator_rate = 0.0135
    group_quarters_rate = 0.0034
    enlisted_personnel_rate = 0.0000
    jblm_rate = 0.0000
    external_rate = 0.0096
    truck_rate = 0.0135

    # Zone system Inputs
    hightaz=3700
    lowstation=3733
    highstation=3750
    lowpnr=3751
    highpnr=4000

    i5_station = 3733

    # Break points for classifications
    # Income in 2014 $'s
    low_income = 37000
    medium_income = 74000
    high_income = 111000

    # Aiport Trip Rates
    air_people = 0.02112
    air_jobs = 0.01486
    

    # Lists for HH and Person Files
    hh_variables=['hhno','hhsize','hhparcel','hhincome']
    person_variables=['pno','hhno','pptyp']

    employment_categories = ['retail','food-services','government','office','services','industrial','education','medical','other','university','total-hh','total-jobs','total-people']

    parcel_file = 'inputs/scenario/landuse/parcels_urbansim.txt'

    output_directory = 'outputs/supplemental'

    my_project = EmmeProject(emme_config['supplemental_project'])

    conn = create_engine('sqlite:///inputs/db/soundcast_inputs.db')

    ###########################################################
    # PSRC Zone System for TAZ joining
    ###########################################################
    df_psrc = pd.read_sql("SELECT * FROM psrc_zones", con=conn)
    df_psrc['taz'] = df_psrc['taz'].astype(int)
    df_psrc = df_psrc.loc[:,['taz','county','jblm','external']]

    ###########################################################
    # Auto External Stations
    ###########################################################
    df_external = pd.read_sql("SELECT * FROM auto_externals", con=conn)
    df_external['taz'] = df_external['taz'].astype(int)
    df_external = df_external.loc[:,['taz','year'] + trip_productions + trip_attractions]
    data_year = int(df_external['year'][0])

    # NOTE: need to scale these measures from a base year

    # Join to full TAZ file to ensure final merging works
    df_external = pd.merge(df_psrc, df_external, on='taz', suffixes=('_x','_y'), how='left')
    df_external.fillna(0,inplace=True)
    df_external.set_index('taz', inplace=True)
    df_external = df_external.loc[:,['year'] + trip_productions + trip_attractions]
    df_external = df_external.astype(float)

    # Calculate the Inputs for the Year of the model      
    if int(config['model_year']) > data_year:
        growth_rate = (1+(external_rate*(int(config['model_year'])-data_year)))
        df_external = df_external * growth_rate

    external_taz = df_external.loc[:,trip_productions + trip_attractions]

    ###########################################################
    # Enlisted Personnel
    ###########################################################
    df_enlisted = pd.read_sql_query("SELECT * FROM enlisted_personnel", con=conn)

    ### FIXME: change Zone to taz in DB
    ####
    df_enlisted['taz'] = df_enlisted['Zone'].copy()

    # Select data for model year only
    df_enlisted = df_enlisted[df_enlisted['year'] == int(config['model_year'])][['taz','military_jobs']]

    # Aggregate enlisted personnel by TAZ
    enlisted_taz = df_enlisted.groupby('taz').sum().reset_index()
    enlisted_taz['taz'] = enlisted_taz['taz'].astype('int')

    # Read in rates and calculate Enlisted Personnel related trips by Purpose
    df_rates = pd.read_sql_query("SELECT * FROM trip_rates", con=conn)

    df_enlisted_rates = df_rates[df_rates['group'] == 'enlisted']
  
    for purpose in trip_attractions:
        enlisted_taz[purpose] = enlisted_taz['military_jobs'] * df_enlisted_rates[purpose].values[0]


    # Join to full TAZ file to ensure final merging works
    enlisted_taz = pd.merge(df_psrc, enlisted_taz, on='taz', suffixes=('_x','_y'), how='left')
    enlisted_taz.fillna(0,inplace=True)
    enlisted_taz.set_index('taz', inplace=True)
    enlisted_taz = enlisted_taz.loc[:,trip_attractions]

    ###########################################################
    # Group Quarters
    ###########################################################
    total_gq_df = pd.read_sql_query("SELECT * FROM group_quarters", con=conn)
    total_gq_df[['dorm_share','military_share','other_share']] = total_gq_df[['dorm_share','military_share','other_share']].astype('float')

    # Calculate the Inputs for the Year of the model
    max_input_year = total_gq_df['year'].max()

    if int(config['model_year']) <= max_input_year:
        total_gq_df = total_gq_df[total_gq_df['year'] == int(config['model_year'])]
        
    else:
        # Factor group quarters at an annual rate
        total_gq_df = total_gq_df[total_gq_df['year'] == int(max_input_year)]
        total_gq_df['group_quarters'] = total_gq_df['group_quarters'] * (1+(group_quarters_rate*(int(config['model_year'])-max_input_year)))

    total_gq_df = total_gq_df[['taz', 'dorm_share', 'military_share', 'other_share', 'group_quarters']]

    total_gq_df['dorms'] = total_gq_df['group_quarters'] * total_gq_df['dorm_share']
    total_gq_df['military'] = total_gq_df['group_quarters'] * total_gq_df['military_share']
    total_gq_df['other'] = total_gq_df['group_quarters'] * total_gq_df['other_share']
   
    # Merge with the Block/Taz dataframe and trim down the columns
    total_gq_df = total_gq_df[['taz','dorms','military','other']]

    # Read in rates and calculate total Group Quarters related trips
    df_gq_rates = df_rates[df_rates['group'] == 'group_quarters']

    for purpose in trip_productions:
        for gq_type in ['dorms','military','other']:
            total_gq_df[purpose] = total_gq_df[gq_type] * df_gq_rates[df_gq_rates['segmentation'] == gq_type][purpose].values[0]

    # Consolidate Group Quarters data to TAZ for output to travel model
    group_quarters_taz = total_gq_df.groupby('taz').sum()
    group_quarters_taz = group_quarters_taz.reset_index()
    group_quarters_taz['taz'] = group_quarters_taz['taz'].apply(int)

    # Join to full TAZ file to ensure final merging works
    group_quarters_taz = pd.merge(df_psrc, group_quarters_taz, on='taz', suffixes=('_x','_y'), how='left')
    group_quarters_taz.fillna(0,inplace=True)
    group_quarters_taz.set_index('taz', inplace=True)
    group_quarters_taz = group_quarters_taz[trip_productions]

    ###########################################################
    ### Joint Base Lewis McChord
    ###########################################################
    jblm_df = pd.read_sql_query("SELECT * FROM jblm_trips", con=conn)
    jblm_matrix = int(jblm_df['matrix_id'][0])
    data_year = int(jblm_df['year'][0])

    keep_columns = ['origin_zone','destination_zone','trips',]
    jblm_df = jblm_df.loc[:,keep_columns]
    jblm_df['trips'] = jblm_df['trips'].apply(float)
       
    if int(config['model_year']) > data_year:
        growth_rate = (1+(jblm_rate*(int(config['model_year'])-data_year)))
        jblm_df['trips'] = jblm_df['trips'] * growth_rate
    
    # Create JBLM Input File for use in Emme
    working_file = open(output_directory+'/jblm.in', "w")
    working_file.write('c ' + str(config['model_year']) + ' Trip Generation' + '\n')
    working_file.write('c JBLM trips are based on gate counts, blue tooth and zipcode survey data' + '\n')
    working_file.write('t matrices' + '\n')
    working_file.write('a matrix=mf' + str(jblm_matrix) + ' jblm ' + '0 JBLM Trips' + '\n')
        
    for rows in range(0, (len(jblm_df))):
            
        origin_zone = jblm_df['origin_zone'][rows]
        destination_zone = jblm_df['destination_zone'][rows]
        working_file.write(' '+str(origin_zone) + ' ' + str(destination_zone) + ' : ' + str(jblm_df['trips'][rows]) + '\n')

    working_file.close()

    ###########################################################
    # Remove JBLM Externals from the Externals dataframe 
    ###########################################################

    # Calculate amount of JBLM traffic that is from/to an external and remove it from the External Station df
    jblm_df['origin_zone'] = jblm_df['origin_zone'].apply(int)
    jblm_df['destination_zone'] = jblm_df['destination_zone'].apply(int)

    jblm_external = jblm_df[(jblm_df['origin_zone'] >=lowstation)]
    jblm_ext_productions = sum(jblm_external['trips'])

    jblm_external = jblm_df[(jblm_df['destination_zone'] >=lowstation)]
    jblm_ext_attractions = sum(jblm_external['trips'])

    # Calculate the total trip productions and attractions for the I-5 Zone
    i5_ext_productions = 0
    for purposes in trip_productions:
        i5_ext_productions = i5_ext_productions + external_taz[purposes][i5_station]

    i5_ext_attractions = 0
    for purposes in trip_attractions:
        i5_ext_attractions = i5_ext_attractions + external_taz[purposes][i5_station]

    # Scale the I-5 station volumes by purpose
    i5_revised_productions = i5_ext_productions - jblm_ext_productions
    i5_revised_attractions = i5_ext_attractions - jblm_ext_attractions

    revised_external_taz = external_taz
    for purposes in trip_productions:
    
        ratio = revised_external_taz[purposes][i5_station] / i5_ext_productions
        revised_external_taz[purposes][i5_station] = i5_revised_productions * ratio

    for purposes in trip_attractions:
    
        ratio = revised_external_taz[purposes][i5_station] / i5_ext_attractions
        revised_external_taz[purposes][i5_station] = i5_revised_attractions * ratio

    ###########################################################
    # Heavy Truck Productions, grown from ATRI data
    ###########################################################
    heavy_trucks = pd.read_sql_query("SELECT * FROM heavy_trucks", con=conn)
    heavy_trucks = heavy_trucks[['taz','year','htkpro','htkatt']]

    # Calculate the Inputs for the Year of the model
    data_year = int(heavy_trucks['year'][0])
    heavy_trucks = heavy_trucks.drop('year',axis=1)
    heavy_trucks['htkpro'] = heavy_trucks['htkpro'].apply(float)
    heavy_trucks['htkatt'] = heavy_trucks['htkatt'].apply(float)
       
    if int(config['model_year']) > data_year:
        growth_rate = (1+(truck_rate*(int(config['model_year'])-data_year)))
        heavy_trucks['htkpro'] = heavy_trucks['htkpro'] * growth_rate
        heavy_trucks['htkatt'] = heavy_trucks['htkatt'] * growth_rate

    # Make the TAZ field the index
    heavy_trucks_taz = heavy_trucks.groupby('taz').sum()
    heavy_trucks_taz = heavy_trucks_taz.reset_index()
    heavy_trucks_taz['taz'] = heavy_trucks_taz['taz'].apply(int)

    # Apply land-use restrictions for productions/attraction in TAZs without appropriate industrial uses
    allowed_tazs = calc_heavy_truck_restrictions()
    external_taz_list = list(range(emme_config['MIN_EXTERNAL'], emme_config['MAX_EXTERNAL'] + 1))
    allowed_tazs = allowed_tazs.tolist() + external_taz_list

    heavy_trucks_taz = heavy_trucks_taz[heavy_trucks_taz['taz'].isin(allowed_tazs)]

    # Join to full TAZ file to ensure final merging works
    heavy_trucks_taz = pd.merge(df_psrc, heavy_trucks_taz, on='taz', suffixes=('_x','_y'), how='left')
    heavy_trucks_taz.fillna(0,inplace=True)
    heavy_trucks_taz = heavy_trucks_taz.loc[:,['taz','htkpro','htkatt']]

    ###########################################################
    # SeaTac Airport 
    ###########################################################
    df_seatac = pd.read_sql_query("SELECT * FROM seatac", con=conn)
    seatac_zone = df_seatac[df_seatac['year'] == int(config['model_year'])]['taz'].values[0]
    seatac_enplanements = df_seatac[df_seatac['year'] == int(config['model_year'])]['enplanements'].values[0]

    ###########################################################
    ## Special Generators
    ###########################################################

    # Special generator trips are assumed of type HBO
    df_special = pd.read_sql_query("SELECT * FROM special_generators", con=conn)

    # Calculate the Inputs for the Year of the model
    max_input_year = df_special['year'].max()

    if int(config['model_year']) <= max_input_year:
        df_special = df_special[df_special['year'] == config['model_year']]
        df_special['hboatt'] = df_special['trips'].astype('float')
        
    else:
        df_special = df_special[df_special['year'] == max_input_year]
        df_special['hboatt'] = df_special[df_special['year'] == max_input_year]['trips'].astype('float')
        df_special['hboatt'] = df_special['hboatt'] * (1+(special_generator_rate*(int(config['model_year'])-max_input_year)))

    df_special = df_special[['taz','hboatt']]
                            
    # Consolidate Special Generator data to TAZ
    special_generators_taz = df_special.groupby('taz').sum()
    special_generators_taz = special_generators_taz.reset_index()
    special_generators_taz['taz'] = special_generators_taz['taz'].apply(int)

    # Join to full TAZ file to ensure final merging works
    special_generators_taz = pd.merge(df_psrc, special_generators_taz, on='taz', suffixes=('_x','_y'), how='left')
    special_generators_taz.fillna(0,inplace=True)
    special_generators_taz.set_index('taz', inplace=True)
    special_generators_taz = special_generators_taz.loc[:,['hboatt']]

    ###########################################################
    # Load Household, Person and Parcel files 
    ###########################################################

    #### FIXME, fix this
    # Parcel Columns to use and what to rename them
    original_parcel_columns =  ['parcelid','xcoord_p','ycoord_p','taz_p','empedu_p','empfoo_p','empgov_p','empind_p','empmed_p','empofc_p','empret_p','emprsc_p','empsvc_p','empoth_p','emptot_p','stugrd_p','stuhgh_p','stuuni_p']
    updated_parcel_columns = ['parcel-id','xcoord','ycoord','taz','education','food-services','government','industrial','medical','office','retail','resources','services','other','total-jobs','k-8','high-school','university']

    hh_person = r'inputs/scenario/landuse/hh_and_persons.h5'
    hh_people = h5py.File(hh_person,'r+') 
    hh_df = create_df_from_h5(hh_people, 'Household', hh_variables)
    person_df = create_df_from_h5(hh_people, 'Person', person_variables)

    parcels = pd.read_csv(parcel_file, sep = ' ')
    parcels.columns = parcels.columns.str.lower()
    parcels = parcels.loc[:,original_parcel_columns]
    parcels.columns = updated_parcel_columns

    ###########################################################
    # Create a Household file with cross classifications
    # using the person and household file
    ###########################################################

    person_df['people'] = 1

    # Flag if the person has a full or part-time job
    person_df['workers'] = 0
    person_df.loc[person_df['pptyp'] == 1, 'workers'] = 1
    person_df.loc[person_df['pptyp'] == 2, 'workers'] = 1 

    # Flag if the person is a school age kid
    person_df['school-age'] = 0
    person_df.loc[person_df['pptyp'] == 6, 'school-age'] = 1
    person_df.loc[person_df['pptyp'] == 7, 'school-age'] = 1   

    # Flag if the person is a college student
    person_df['college-student'] = 0
    person_df.loc[person_df['pptyp'] == 5, 'college-student'] = 1
             
    # Remove a couple columns
    fields_to_remove=['pno','pptyp']
    person_df = person_df.drop(fields_to_remove,axis=1)
             
    # Create a HH file by grouping the person file by household number 
    df_hh = person_df.groupby('hhno').sum()
    df_hh = df_hh.reset_index()

    # Merge the HH File created from the persons with the original HH file from H5
    df_hh = pd.merge(df_hh,hh_df,on='hhno',suffixes=('_x','_y'),how='left')

    # Create a Column for Household sizes 1, 2, 3 or 4+
    df_hh['household-class'] = df_hh['hhsize']
    df_hh.loc[df_hh['household-class'] > 4, 'household-class'] = 4
         
    # Create a Column for workers 0, 1, 2 or 3+
    df_hh['worker-class'] = df_hh['workers']
    df_hh.loc[df_hh['worker-class'] > 3, 'worker-class'] = 3       

    # Create a Column for Income 1, 2 ,3 or 4
    df_hh['income-class'] = 0
    df_hh.loc[df_hh['hhincome'] <= low_income, 'income-class'] = 1 
    df_hh.loc[(df_hh['hhincome'] > low_income) & (df_hh['hhincome'] <= medium_income), 'income-class'] = 2 
    df_hh.loc[(df_hh['hhincome'] > medium_income) & (df_hh['hhincome'] <= high_income), 'income-class'] = 3         
    df_hh.loc[df_hh['hhincome'] > high_income, 'income-class'] = 4
         
    # Create a Column for school age children 0, 1, 2 or 3+
    df_hh['school-class'] = df_hh['school-age']
    df_hh.loc[df_hh['school-class'] > 3, 'school-class'] = 3          

    # Create a Column for college age persons 0, 1, 2+ 
    df_hh['college-class'] = df_hh['college-student']
    df_hh.loc[df_hh['college-class'] > 2, 'college-class'] = 2          
         
    # Create a Columns for Household - Work - Income Cross-Classification, Income & School and Income and College
    df_hh['hwi'] = 'h'+ df_hh['household-class'].apply(str) + 'w' + df_hh['worker-class'].apply(str) + 'i' + df_hh['income-class'].apply(str)
    df_hh['si'] = 's'+ df_hh['school-class'].apply(str) + 'i' + df_hh['income-class'].apply(str)
    df_hh['ci'] = 'c'+ df_hh['college-class'].apply(str) + 'i' + df_hh['income-class'].apply(str)

    ###########################################################
    # Household trip production
    ###########################################################
    df_hh_rates = df_rates[df_rates['group'] == 'household'].drop(['schpro','schatt','colpro','colatt'], axis=1)
    df_sch_rates = df_rates[df_rates['group'] == 'school'][['segmentation','schpro','schatt']]
    df_coll_rates = df_rates[df_rates['group'] == 'college'][['segmentation','colpro','colatt']]


    # Merge Rates with Households by Cross-Classification so we end up with total household productions
    df_hh = pd.merge(df_hh,df_hh_rates,left_on='hwi',right_on='segmentation',suffixes=('_x','_y'),how='left')
    df_hh = pd.merge(df_hh,df_sch_rates,left_on='si',right_on='segmentation',suffixes=('_x','_y'),how='left')
    df_hh = pd.merge(df_hh,df_coll_rates,left_on='si',right_on='segmentation',suffixes=('_x','_y'),how='left')
    df_hh = df_hh.loc[:,trip_productions + trip_attractions + ['hhparcel','people']]
    df_hh['total-hh'] = 1

    ###########################################################
    # Combine HH Trip Generation with Parcels
    ###########################################################
    df_parcel_hh_pa = df_hh.groupby('hhparcel').sum()
    df_parcel_hh_pa = df_parcel_hh_pa.reset_index()
    df_parcel_hh_pa.rename(columns={'hhparcel': 'parcel-id','people': 'total-people'}, inplace=True)

    ###########################################################
    # Parcel trip attractions
    ###########################################################
    df_parcels = pd.merge(parcels, df_parcel_hh_pa, on='parcel-id', suffixes=('_x','_y'), how='left')
    df_parcels.fillna(0,inplace=True)

    # Create a couple columns for trip attractions for parcels
    df_parcels['education'] = df_parcels['k-8'] + df_parcels['high-school']
    df_parcels['mtkpro'] = 0
    df_parcels['mtkatt'] = 0
    df_parcels['cvhpro'] = 0
    df_parcels['cvhatt'] = 0
    df_parcels['dtkatt'] = 0
    df_parcels['dtkpro'] = 0

    # Trip Attractions based on employment categories
    df_job_attraction_rates = pd.read_sql_query("SELECT * FROM job_attractions", con=conn)
    df_job_attraction_rates.set_index('employment-type', inplace=True)
    attraction_purposes = trip_attractions + ['cvhatt','mtkatt','dtkatt']

    for purpose in attraction_purposes:
    
        for jobs in employment_categories:
            df_parcels[purpose] = df_parcels[purpose] + (df_parcels[jobs] * df_job_attraction_rates.loc[jobs,purpose])

    # Trip Productions based on employment categories
    df_job_production_rates = pd.read_sql_query("SELECT * FROM job_productions", con=conn)
    df_job_production_rates.set_index('employment-type', inplace=True)
    productions_purposes = trip_productions + ['cvhpro','mtkpro','dtkpro']

    for purpose in productions_purposes:
    
        for jobs in employment_categories:
            df_parcels[purpose] = df_parcels[purpose] + (df_parcels[jobs] * df_job_production_rates.loc[jobs,purpose])

    # Scale delivery productions based on a target number of delivery trips
    df_parcels['dtkpro'] = emme_config['total_delivery_trips']*(df_parcels['dtkpro']/df_parcels['dtkpro'].sum())

    ###########################################################
    # SeaTac Airport trip generation
    ###########################################################
    df_parcels['airport'] = (df_parcels['total-jobs']*air_jobs) + (df_parcels['total-people']*air_people)
    aiport_balancing = seatac_enplanements / sum(df_parcels['airport'])
    df_parcels['airport'] = df_parcels['airport']*aiport_balancing

    ###########################################################
    # Create TAZ Input files
    ###########################################################
    df_taz = df_parcels.groupby('taz').sum()
    df_taz = df_taz.reset_index()
    df_taz.fillna(0,inplace=True)
    df_taz['taz'] = df_taz['taz'].apply(int)

    # Join to full TAZ file to ensure final merging works
    df_taz = pd.merge(df_psrc, df_taz, on='taz', suffixes=('_x','_y'), how='left')
    df_taz.fillna(0,inplace=True)

    # Create a Kitsap County flag for use in Kitsap Adjustments
    df_taz['kitsap']=0
    df_taz.loc[df_taz['county'] == 'Kitsap', 'kitsap'] = 1

    # Add in Heavy Truck Productions and Attractions
    df_taz = pd.merge(df_taz, heavy_trucks_taz, on='taz', suffixes=('_x','_y'), how='left')
    df_taz.fillna(0,inplace=True)

    # Clean up dataframe for further calculations as well as output
    df_taz.set_index('taz', inplace=True)
    df_taz = df_taz.loc[:,trip_productions + ['cvhpro','mtkpro','htkpro','dtkpro'] + trip_attractions + ['cvhatt','mtkatt','htkatt','dtkatt','airport','kitsap','jblm']]
    df_taz.to_csv(output_directory+'/1_unadjusted_unbalanced.csv',index=True)

    # Add in the Group Quarters to Trip Productions   
    for purpose in trip_productions:
        df_taz[purpose] = df_taz[purpose] + group_quarters_taz[purpose]
    df_taz.to_csv(output_directory+'/2_add_group_quarters.csv',index=True)

    # Add in the Enlisted Personnel to Trip Attractions
    for purpose in trip_attractions:
        df_taz[purpose] = df_taz[purpose] + enlisted_taz[purpose]
    df_taz.to_csv(output_directory+'/3_add_enlisted_personnel.csv',index=True)

    # Add in the Special Generators to Trip Attractions
    df_taz['hboatt'] = df_taz['hboatt'] + special_generators_taz['hboatt']
    df_taz.to_csv(output_directory+'/4_add_special_generators.csv',index=True)

    # Add in the External Trips
    all_purposes = trip_productions + trip_attractions
    for purpose in all_purposes:
        df_taz[purpose] = df_taz[purpose] + revised_external_taz[purpose]
    df_taz.to_csv(output_directory+'/5_add_externals.csv',index=True)

    #Soundcast uses pre-determined HSP trips to meet external counts. Need to adjust these here for non-work-ixxi:
    external_trip_table =  pd.read_sql('SELECT * FROM externals_unadjusted', con=conn) 
    external_trip_table.set_index('taz', inplace = True)
    external_trip_table = external_trip_table[['hsppro', 'hspatt']]
    df_taz.update(external_trip_table)


    # Zero out JBLM trips that were generated above (so only inlcude Shopping, HBO, OtO and WtO)
    df_taz['jblm'] = df_taz['jblm'].apply(int)
    jblm_purposes = ['hbw1pro','hbw2pro','hbw3pro','hbw4pro','colpro','schpro','cvhpro','mtkpro','htkpro',
                     'hbw1att','hbw2att','hbw3att','hbw4att','colatt','schatt','cvhatt','mtkatt','htkatt']

    for purposes in jblm_purposes:
        df_taz.loc[df_taz['jblm'] == 1, purposes] = 0

    # Adjust the taz level data based on trip rate adjustments
    df_rate_adjustments = pd.read_sql_query("SELECT * FROM rate_adjustments", con=conn)
    df_rate_adjustments.set_index('trip-purpose', inplace=True)
    all_purposes = trip_productions + ['cvhpro','mtkpro','htkpro'] + trip_attractions + ['cvhatt','mtkatt','htkatt']

    # Adjust Productions and Attractions by Adjustment Factors
    for purpose in all_purposes:
        df_taz[purpose] = df_taz[purpose] * [df_rate_adjustments.loc[purpose,'regional']]
        df_taz[purpose] = df_taz[purpose] + (df_taz[purpose] * [df_rate_adjustments.loc[purpose,'kitsap']]*df_taz['kitsap'])

    df_taz.to_csv(output_directory+'/6_adjust_trip_ends.csv',index=True)

    # Balance the taz dataframe
    balanced_df = balance_trips(df_taz, balance_to_productions, 'pro')
    balanced_df = balance_trips(df_taz, balance_to_attractions, 'att')
    balanced_df.to_csv(output_directory+'/7_balance_trip_ends.csv',index=True)


if __name__ == "__main__":
    main()